{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyspark in c:\\spark\\spark-3.2.4-bin-hadoop3.2\\python (3.2.4)\n",
      "Requirement already satisfied: py4j==0.10.9.5 in c:\\users\\acer\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from pyspark) (0.10.9.5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 20.2.3; however, version 23.3.1 is available.\n",
      "You should consider upgrading via the 'c:\\users\\acer\\appdata\\local\\programs\\python\\python39\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\acer\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (2.1.4)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\acer\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from pandas) (2023.3.post1)\n",
      "Requirement already satisfied: numpy<2,>=1.22.4; python_version < \"3.11\" in c:\\users\\acer\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from pandas) (1.26.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\acer\\appdata\\roaming\\python\\python39\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\acer\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\acer\\appdata\\roaming\\python\\python39\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 20.2.3; however, version 23.3.1 is available.\n",
      "You should consider upgrading via the 'c:\\users\\acer\\appdata\\local\\programs\\python\\python39\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting findspark\n",
      "  Using cached findspark-2.0.1-py2.py3-none-any.whl (4.4 kB)\n",
      "Installing collected packages: findspark\n",
      "Successfully installed findspark-2.0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 20.2.3; however, version 23.3.1 is available.\n",
      "You should consider upgrading via the 'c:\\users\\acer\\appdata\\local\\programs\\python\\python39\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "!pip install pyspark\n",
    "!pip install pandas\n",
    "!pip install findspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "import pandas as pd\n",
    "\n",
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>work_year</th>\n",
       "      <th>experience_level</th>\n",
       "      <th>employment_type</th>\n",
       "      <th>job_title</th>\n",
       "      <th>salary</th>\n",
       "      <th>salary_currency</th>\n",
       "      <th>salary_in_usd</th>\n",
       "      <th>employee_residence</th>\n",
       "      <th>remote_ratio</th>\n",
       "      <th>company_location</th>\n",
       "      <th>company_size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023</td>\n",
       "      <td>SE</td>\n",
       "      <td>FT</td>\n",
       "      <td>Principal Data Scientist</td>\n",
       "      <td>80000</td>\n",
       "      <td>EUR</td>\n",
       "      <td>85847</td>\n",
       "      <td>ES</td>\n",
       "      <td>100</td>\n",
       "      <td>ES</td>\n",
       "      <td>L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023</td>\n",
       "      <td>MI</td>\n",
       "      <td>CT</td>\n",
       "      <td>ML Engineer</td>\n",
       "      <td>30000</td>\n",
       "      <td>USD</td>\n",
       "      <td>30000</td>\n",
       "      <td>US</td>\n",
       "      <td>100</td>\n",
       "      <td>US</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023</td>\n",
       "      <td>MI</td>\n",
       "      <td>CT</td>\n",
       "      <td>ML Engineer</td>\n",
       "      <td>25500</td>\n",
       "      <td>USD</td>\n",
       "      <td>25500</td>\n",
       "      <td>US</td>\n",
       "      <td>100</td>\n",
       "      <td>US</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023</td>\n",
       "      <td>SE</td>\n",
       "      <td>FT</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>175000</td>\n",
       "      <td>USD</td>\n",
       "      <td>175000</td>\n",
       "      <td>CA</td>\n",
       "      <td>100</td>\n",
       "      <td>CA</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023</td>\n",
       "      <td>SE</td>\n",
       "      <td>FT</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>120000</td>\n",
       "      <td>USD</td>\n",
       "      <td>120000</td>\n",
       "      <td>CA</td>\n",
       "      <td>100</td>\n",
       "      <td>CA</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2023</td>\n",
       "      <td>SE</td>\n",
       "      <td>FT</td>\n",
       "      <td>Applied Scientist</td>\n",
       "      <td>222200</td>\n",
       "      <td>USD</td>\n",
       "      <td>222200</td>\n",
       "      <td>US</td>\n",
       "      <td>0</td>\n",
       "      <td>US</td>\n",
       "      <td>L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2023</td>\n",
       "      <td>SE</td>\n",
       "      <td>FT</td>\n",
       "      <td>Applied Scientist</td>\n",
       "      <td>136000</td>\n",
       "      <td>USD</td>\n",
       "      <td>136000</td>\n",
       "      <td>US</td>\n",
       "      <td>0</td>\n",
       "      <td>US</td>\n",
       "      <td>L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2023</td>\n",
       "      <td>SE</td>\n",
       "      <td>FT</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>219000</td>\n",
       "      <td>USD</td>\n",
       "      <td>219000</td>\n",
       "      <td>CA</td>\n",
       "      <td>0</td>\n",
       "      <td>CA</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2023</td>\n",
       "      <td>SE</td>\n",
       "      <td>FT</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>141000</td>\n",
       "      <td>USD</td>\n",
       "      <td>141000</td>\n",
       "      <td>CA</td>\n",
       "      <td>0</td>\n",
       "      <td>CA</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2023</td>\n",
       "      <td>SE</td>\n",
       "      <td>FT</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>147100</td>\n",
       "      <td>USD</td>\n",
       "      <td>147100</td>\n",
       "      <td>US</td>\n",
       "      <td>0</td>\n",
       "      <td>US</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   work_year experience_level employment_type                 job_title  \\\n",
       "0       2023               SE              FT  Principal Data Scientist   \n",
       "1       2023               MI              CT               ML Engineer   \n",
       "2       2023               MI              CT               ML Engineer   \n",
       "3       2023               SE              FT            Data Scientist   \n",
       "4       2023               SE              FT            Data Scientist   \n",
       "5       2023               SE              FT         Applied Scientist   \n",
       "6       2023               SE              FT         Applied Scientist   \n",
       "7       2023               SE              FT            Data Scientist   \n",
       "8       2023               SE              FT            Data Scientist   \n",
       "9       2023               SE              FT            Data Scientist   \n",
       "\n",
       "   salary salary_currency  salary_in_usd employee_residence  remote_ratio  \\\n",
       "0   80000             EUR          85847                 ES           100   \n",
       "1   30000             USD          30000                 US           100   \n",
       "2   25500             USD          25500                 US           100   \n",
       "3  175000             USD         175000                 CA           100   \n",
       "4  120000             USD         120000                 CA           100   \n",
       "5  222200             USD         222200                 US             0   \n",
       "6  136000             USD         136000                 US             0   \n",
       "7  219000             USD         219000                 CA             0   \n",
       "8  141000             USD         141000                 CA             0   \n",
       "9  147100             USD         147100                 US             0   \n",
       "\n",
       "  company_location company_size  \n",
       "0               ES            L  \n",
       "1               US            S  \n",
       "2               US            S  \n",
       "3               CA            M  \n",
       "4               CA            M  \n",
       "5               US            L  \n",
       "6               US            L  \n",
       "7               CA            M  \n",
       "8               CA            M  \n",
       "9               US            M  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data = pd.read_csv(\"./data/ds_salaries.csv\")\n",
    "# data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark import SparkContext\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName('Assignment').getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://172.26.0.129:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.2.4</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Assignment</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x1f5411be730>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------------+---------------+--------------------+------+---------------+-------------+------------------+------------+----------------+------------+\n",
      "|      _c0|             _c1|            _c2|                 _c3|   _c4|            _c5|          _c6|               _c7|         _c8|             _c9|        _c10|\n",
      "+---------+----------------+---------------+--------------------+------+---------------+-------------+------------------+------------+----------------+------------+\n",
      "|work_year|experience_level|employment_type|           job_title|salary|salary_currency|salary_in_usd|employee_residence|remote_ratio|company_location|company_size|\n",
      "|     2023|              SE|             FT|Principal Data Sc...| 80000|            EUR|        85847|                ES|         100|              ES|           L|\n",
      "|     2023|              MI|             CT|         ML Engineer| 30000|            USD|        30000|                US|         100|              US|           S|\n",
      "|     2023|              MI|             CT|         ML Engineer| 25500|            USD|        25500|                US|         100|              US|           S|\n",
      "|     2023|              SE|             FT|      Data Scientist|175000|            USD|       175000|                CA|         100|              CA|           M|\n",
      "|     2023|              SE|             FT|      Data Scientist|120000|            USD|       120000|                CA|         100|              CA|           M|\n",
      "|     2023|              SE|             FT|   Applied Scientist|222200|            USD|       222200|                US|           0|              US|           L|\n",
      "|     2023|              SE|             FT|   Applied Scientist|136000|            USD|       136000|                US|           0|              US|           L|\n",
      "|     2023|              SE|             FT|      Data Scientist|219000|            USD|       219000|                CA|           0|              CA|           M|\n",
      "|     2023|              SE|             FT|      Data Scientist|141000|            USD|       141000|                CA|           0|              CA|           M|\n",
      "|     2023|              SE|             FT|      Data Scientist|147100|            USD|       147100|                US|           0|              US|           M|\n",
      "|     2023|              SE|             FT|      Data Scientist| 90700|            USD|        90700|                US|           0|              US|           M|\n",
      "|     2023|              SE|             FT|        Data Analyst|130000|            USD|       130000|                US|         100|              US|           M|\n",
      "|     2023|              SE|             FT|        Data Analyst|100000|            USD|       100000|                US|         100|              US|           M|\n",
      "|     2023|              EN|             FT|   Applied Scientist|213660|            USD|       213660|                US|           0|              US|           L|\n",
      "|     2023|              EN|             FT|   Applied Scientist|130760|            USD|       130760|                US|           0|              US|           L|\n",
      "|     2023|              SE|             FT|        Data Modeler|147100|            USD|       147100|                US|           0|              US|           M|\n",
      "|     2023|              SE|             FT|        Data Modeler| 90700|            USD|        90700|                US|           0|              US|           M|\n",
      "|     2023|              SE|             FT|      Data Scientist|170000|            USD|       170000|                US|           0|              US|           M|\n",
      "|     2023|              SE|             FT|      Data Scientist|150000|            USD|       150000|                US|           0|              US|           M|\n",
      "+---------+----------------+---------------+--------------------+------+---------------+-------------+------------------+------------+----------------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark = spark.read.csv(\"./data/ds_salaries.csv\");\n",
    "df_pyspark.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### parallelize example\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [1,2,3,4,5]\n",
    "rdd = sc.parallelize(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "map(): [2, 4, 6, 8, 10]\n"
     ]
    }
   ],
   "source": [
    "data = [1,2,3,4,5]\n",
    "rdd = sc.parallelize(data)\n",
    "squred_root = rdd.map(lambda x: x*2);\n",
    "# print(\"first()\", squred_root.first());\n",
    "print(\"map():\", squred_root.collect())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load dataset with header as column names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------------+---------------+--------------------+------+---------------+-------------+------------------+------------+----------------+------------+\n",
      "|work_year|experience_level|employment_type|           job_title|salary|salary_currency|salary_in_usd|employee_residence|remote_ratio|company_location|company_size|\n",
      "+---------+----------------+---------------+--------------------+------+---------------+-------------+------------------+------------+----------------+------------+\n",
      "|     2023|              SE|             FT|Principal Data Sc...| 80000|            EUR|        85847|                ES|         100|              ES|           L|\n",
      "|     2023|              MI|             CT|         ML Engineer| 30000|            USD|        30000|                US|         100|              US|           S|\n",
      "|     2023|              MI|             CT|         ML Engineer| 25500|            USD|        25500|                US|         100|              US|           S|\n",
      "|     2023|              SE|             FT|      Data Scientist|175000|            USD|       175000|                CA|         100|              CA|           M|\n",
      "|     2023|              SE|             FT|      Data Scientist|120000|            USD|       120000|                CA|         100|              CA|           M|\n",
      "|     2023|              SE|             FT|   Applied Scientist|222200|            USD|       222200|                US|           0|              US|           L|\n",
      "|     2023|              SE|             FT|   Applied Scientist|136000|            USD|       136000|                US|           0|              US|           L|\n",
      "|     2023|              SE|             FT|      Data Scientist|219000|            USD|       219000|                CA|           0|              CA|           M|\n",
      "|     2023|              SE|             FT|      Data Scientist|141000|            USD|       141000|                CA|           0|              CA|           M|\n",
      "|     2023|              SE|             FT|      Data Scientist|147100|            USD|       147100|                US|           0|              US|           M|\n",
      "|     2023|              SE|             FT|      Data Scientist| 90700|            USD|        90700|                US|           0|              US|           M|\n",
      "|     2023|              SE|             FT|        Data Analyst|130000|            USD|       130000|                US|         100|              US|           M|\n",
      "|     2023|              SE|             FT|        Data Analyst|100000|            USD|       100000|                US|         100|              US|           M|\n",
      "|     2023|              EN|             FT|   Applied Scientist|213660|            USD|       213660|                US|           0|              US|           L|\n",
      "|     2023|              EN|             FT|   Applied Scientist|130760|            USD|       130760|                US|           0|              US|           L|\n",
      "|     2023|              SE|             FT|        Data Modeler|147100|            USD|       147100|                US|           0|              US|           M|\n",
      "|     2023|              SE|             FT|        Data Modeler| 90700|            USD|        90700|                US|           0|              US|           M|\n",
      "|     2023|              SE|             FT|      Data Scientist|170000|            USD|       170000|                US|           0|              US|           M|\n",
      "|     2023|              SE|             FT|      Data Scientist|150000|            USD|       150000|                US|           0|              US|           M|\n",
      "|     2023|              MI|             FT|        Data Analyst|150000|            USD|       150000|                US|         100|              US|           M|\n",
      "+---------+----------------+---------------+--------------------+------+---------------+-------------+------------------+------------+----------------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark_data = spark.read.option('header', 'true').csv(\"./data/ds_salaries.csv\")\n",
    "spark_data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(work_year='2023', experience_level='SE', employment_type='FT', job_title='Principal Data Scientist', salary='80000', salary_currency='EUR', salary_in_usd='85847', employee_residence='ES', remote_ratio='100', company_location='ES', company_size='L'),\n",
       " Row(work_year='2023', experience_level='MI', employment_type='CT', job_title='ML Engineer', salary='30000', salary_currency='USD', salary_in_usd='30000', employee_residence='US', remote_ratio='100', company_location='US', company_size='S'),\n",
       " Row(work_year='2023', experience_level='MI', employment_type='CT', job_title='ML Engineer', salary='25500', salary_currency='USD', salary_in_usd='25500', employee_residence='US', remote_ratio='100', company_location='US', company_size='S'),\n",
       " Row(work_year='2023', experience_level='SE', employment_type='FT', job_title='Data Scientist', salary='175000', salary_currency='USD', salary_in_usd='175000', employee_residence='CA', remote_ratio='100', company_location='CA', company_size='M'),\n",
       " Row(work_year='2023', experience_level='SE', employment_type='FT', job_title='Data Scientist', salary='120000', salary_currency='USD', salary_in_usd='120000', employee_residence='CA', remote_ratio='100', company_location='CA', company_size='M'),\n",
       " Row(work_year='2023', experience_level='SE', employment_type='FT', job_title='Applied Scientist', salary='222200', salary_currency='USD', salary_in_usd='222200', employee_residence='US', remote_ratio='0', company_location='US', company_size='L'),\n",
       " Row(work_year='2023', experience_level='SE', employment_type='FT', job_title='Applied Scientist', salary='136000', salary_currency='USD', salary_in_usd='136000', employee_residence='US', remote_ratio='0', company_location='US', company_size='L'),\n",
       " Row(work_year='2023', experience_level='SE', employment_type='FT', job_title='Data Scientist', salary='219000', salary_currency='USD', salary_in_usd='219000', employee_residence='CA', remote_ratio='0', company_location='CA', company_size='M'),\n",
       " Row(work_year='2023', experience_level='SE', employment_type='FT', job_title='Data Scientist', salary='141000', salary_currency='USD', salary_in_usd='141000', employee_residence='CA', remote_ratio='0', company_location='CA', company_size='M'),\n",
       " Row(work_year='2023', experience_level='SE', employment_type='FT', job_title='Data Scientist', salary='147100', salary_currency='USD', salary_in_usd='147100', employee_residence='US', remote_ratio='0', company_location='US', company_size='M')]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark_data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[summary: string, work_year: string, experience_level: string, employment_type: string, job_title: string, salary: string, salary_currency: string, salary_in_usd: string, employee_residence: string, remote_ratio: string, company_location: string, company_size: string]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark_data.describe().limit(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'describeSchema'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mspark_data\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdescribeSchema\u001b[49m()\n",
      "File \u001b[1;32mC:\\spark\\spark-3.2.4-bin-hadoop3.2-scala2.13\\python\\pyspark\\sql\\dataframe.py:1659\u001b[0m, in \u001b[0;36mDataFrame.__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   1649\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Returns the :class:`Column` denoted by ``name``.\u001b[39;00m\n\u001b[0;32m   1650\u001b[0m \n\u001b[0;32m   1651\u001b[0m \u001b[38;5;124;03m.. versionadded:: 1.3.0\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1656\u001b[0m \u001b[38;5;124;03m[Row(age=2), Row(age=5)]\u001b[39;00m\n\u001b[0;32m   1657\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1658\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns:\n\u001b[1;32m-> 1659\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\n\u001b[0;32m   1660\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, name))\n\u001b[0;32m   1661\u001b[0m jc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jdf\u001b[38;5;241m.\u001b[39mapply(name)\n\u001b[0;32m   1662\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m Column(jc)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'describeSchema'"
     ]
    }
   ],
   "source": [
    "spark_data.describeSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(work_year_missing=0, experience_level_missing=0, employment_type_missing=0, job_title_missing=0, salary_missing=0, salary_currency_missing=0, salary_in_usd_missing=0, employee_residence_missing=0, remote_ratio_missing=0, company_location_missing=0, company_size_missing=0)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_missing  = spark_data.agg(*[sum(col(c).isNull().cast('int')).alias(c + '_missing') for c in spark_data.columns]).collect()[0]\n",
    "n_missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_col = \"experience_level\"\n",
    "data = spark_data.select(n_col).dropna().rdd.flatMap(lambda x: x).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m plt\u001b[38;5;241m.\u001b[39mhist(\u001b[43mdata\u001b[49m, bins \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m20\u001b[39m , color \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mblue\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      3\u001b[0m plt\u001b[38;5;241m.\u001b[39mtitle(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mHistogram of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn_col\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      4\u001b[0m plt\u001b[38;5;241m.\u001b[39mxlabel(n_col)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'data' is not defined"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.hist(data, bins = 20 , color = 'blue')\n",
    "plt.title(f'Histogram of {n_col}')\n",
    "plt.xlabel(n_col)\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>work_year</th>\n",
       "      <th>experience_level</th>\n",
       "      <th>employment_type</th>\n",
       "      <th>job_title</th>\n",
       "      <th>salary</th>\n",
       "      <th>salary_currency</th>\n",
       "      <th>salary_in_usd</th>\n",
       "      <th>employee_residence</th>\n",
       "      <th>remote_ratio</th>\n",
       "      <th>company_location</th>\n",
       "      <th>company_size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>work_year</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.094724</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.228290</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.236430</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>experience_level</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>employment_type</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>job_title</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>salary</th>\n",
       "      <td>-0.094724</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.023676</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.028731</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>salary_currency</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>salary_in_usd</th>\n",
       "      <td>0.228290</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.023676</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.064171</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>employee_residence</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>remote_ratio</th>\n",
       "      <td>-0.236430</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.028731</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.064171</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>company_location</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>company_size</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    work_year  experience_level  employment_type  job_title  \\\n",
       "work_year            1.000000               NaN              NaN        NaN   \n",
       "experience_level          NaN               NaN              NaN        NaN   \n",
       "employment_type           NaN               NaN              NaN        NaN   \n",
       "job_title                 NaN               NaN              NaN        NaN   \n",
       "salary              -0.094724               NaN              NaN        NaN   \n",
       "salary_currency           NaN               NaN              NaN        NaN   \n",
       "salary_in_usd        0.228290               NaN              NaN        NaN   \n",
       "employee_residence        NaN               NaN              NaN        NaN   \n",
       "remote_ratio        -0.236430               NaN              NaN        NaN   \n",
       "company_location          NaN               NaN              NaN        NaN   \n",
       "company_size              NaN               NaN              NaN        NaN   \n",
       "\n",
       "                      salary  salary_currency  salary_in_usd  \\\n",
       "work_year          -0.094724              NaN       0.228290   \n",
       "experience_level         NaN              NaN            NaN   \n",
       "employment_type          NaN              NaN            NaN   \n",
       "job_title                NaN              NaN            NaN   \n",
       "salary              1.000000              NaN      -0.023676   \n",
       "salary_currency          NaN              NaN            NaN   \n",
       "salary_in_usd      -0.023676              NaN       1.000000   \n",
       "employee_residence       NaN              NaN            NaN   \n",
       "remote_ratio        0.028731              NaN      -0.064171   \n",
       "company_location         NaN              NaN            NaN   \n",
       "company_size             NaN              NaN            NaN   \n",
       "\n",
       "                    employee_residence  remote_ratio  company_location  \\\n",
       "work_year                          NaN     -0.236430               NaN   \n",
       "experience_level                   NaN           NaN               NaN   \n",
       "employment_type                    NaN           NaN               NaN   \n",
       "job_title                          NaN           NaN               NaN   \n",
       "salary                             NaN      0.028731               NaN   \n",
       "salary_currency                    NaN           NaN               NaN   \n",
       "salary_in_usd                      NaN     -0.064171               NaN   \n",
       "employee_residence                 NaN           NaN               NaN   \n",
       "remote_ratio                       NaN      1.000000               NaN   \n",
       "company_location                   NaN           NaN               NaN   \n",
       "company_size                       NaN           NaN               NaN   \n",
       "\n",
       "                    company_size  \n",
       "work_year                    NaN  \n",
       "experience_level             NaN  \n",
       "employment_type              NaN  \n",
       "job_title                    NaN  \n",
       "salary                       NaN  \n",
       "salary_currency              NaN  \n",
       "salary_in_usd                NaN  \n",
       "employee_residence           NaN  \n",
       "remote_ratio                 NaN  \n",
       "company_location             NaN  \n",
       "company_size                 NaN  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cor_matrix = spark_data.select([col(c).cast(\"float\") for c in spark_data.columns]).toPandas().corr()\n",
    "cor_matrix"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
