{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyspark in c:\\spark\\spark-3.2.4-bin-hadoop3.2\\python (3.2.4)\n",
      "Requirement already satisfied: py4j==0.10.9.5 in c:\\users\\acer\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from pyspark) (0.10.9.5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 20.2.3; however, version 23.3.1 is available.\n",
      "You should consider upgrading via the 'c:\\users\\acer\\appdata\\local\\programs\\python\\python39\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\acer\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (2.1.4)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\acer\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from pandas) (2023.3.post1)\n",
      "Requirement already satisfied: numpy<2,>=1.22.4; python_version < \"3.11\" in c:\\users\\acer\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from pandas) (1.26.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\acer\\appdata\\roaming\\python\\python39\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\acer\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\acer\\appdata\\roaming\\python\\python39\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 20.2.3; however, version 23.3.1 is available.\n",
      "You should consider upgrading via the 'c:\\users\\acer\\appdata\\local\\programs\\python\\python39\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting findspark\n",
      "  Using cached findspark-2.0.1-py2.py3-none-any.whl (4.4 kB)\n",
      "Installing collected packages: findspark\n",
      "Successfully installed findspark-2.0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 20.2.3; however, version 23.3.1 is available.\n",
      "You should consider upgrading via the 'c:\\users\\acer\\appdata\\local\\programs\\python\\python39\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "!pip install pyspark\n",
    "!pip install pandas\n",
    "!pip install findspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "import pandas as pd\n",
    "\n",
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>work_year</th>\n",
       "      <th>experience_level</th>\n",
       "      <th>employment_type</th>\n",
       "      <th>job_title</th>\n",
       "      <th>salary</th>\n",
       "      <th>salary_currency</th>\n",
       "      <th>salary_in_usd</th>\n",
       "      <th>employee_residence</th>\n",
       "      <th>remote_ratio</th>\n",
       "      <th>company_location</th>\n",
       "      <th>company_size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023</td>\n",
       "      <td>SE</td>\n",
       "      <td>FT</td>\n",
       "      <td>Principal Data Scientist</td>\n",
       "      <td>80000</td>\n",
       "      <td>EUR</td>\n",
       "      <td>85847</td>\n",
       "      <td>ES</td>\n",
       "      <td>100</td>\n",
       "      <td>ES</td>\n",
       "      <td>L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023</td>\n",
       "      <td>MI</td>\n",
       "      <td>CT</td>\n",
       "      <td>ML Engineer</td>\n",
       "      <td>30000</td>\n",
       "      <td>USD</td>\n",
       "      <td>30000</td>\n",
       "      <td>US</td>\n",
       "      <td>100</td>\n",
       "      <td>US</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023</td>\n",
       "      <td>MI</td>\n",
       "      <td>CT</td>\n",
       "      <td>ML Engineer</td>\n",
       "      <td>25500</td>\n",
       "      <td>USD</td>\n",
       "      <td>25500</td>\n",
       "      <td>US</td>\n",
       "      <td>100</td>\n",
       "      <td>US</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023</td>\n",
       "      <td>SE</td>\n",
       "      <td>FT</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>175000</td>\n",
       "      <td>USD</td>\n",
       "      <td>175000</td>\n",
       "      <td>CA</td>\n",
       "      <td>100</td>\n",
       "      <td>CA</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023</td>\n",
       "      <td>SE</td>\n",
       "      <td>FT</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>120000</td>\n",
       "      <td>USD</td>\n",
       "      <td>120000</td>\n",
       "      <td>CA</td>\n",
       "      <td>100</td>\n",
       "      <td>CA</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2023</td>\n",
       "      <td>SE</td>\n",
       "      <td>FT</td>\n",
       "      <td>Applied Scientist</td>\n",
       "      <td>222200</td>\n",
       "      <td>USD</td>\n",
       "      <td>222200</td>\n",
       "      <td>US</td>\n",
       "      <td>0</td>\n",
       "      <td>US</td>\n",
       "      <td>L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2023</td>\n",
       "      <td>SE</td>\n",
       "      <td>FT</td>\n",
       "      <td>Applied Scientist</td>\n",
       "      <td>136000</td>\n",
       "      <td>USD</td>\n",
       "      <td>136000</td>\n",
       "      <td>US</td>\n",
       "      <td>0</td>\n",
       "      <td>US</td>\n",
       "      <td>L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2023</td>\n",
       "      <td>SE</td>\n",
       "      <td>FT</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>219000</td>\n",
       "      <td>USD</td>\n",
       "      <td>219000</td>\n",
       "      <td>CA</td>\n",
       "      <td>0</td>\n",
       "      <td>CA</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2023</td>\n",
       "      <td>SE</td>\n",
       "      <td>FT</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>141000</td>\n",
       "      <td>USD</td>\n",
       "      <td>141000</td>\n",
       "      <td>CA</td>\n",
       "      <td>0</td>\n",
       "      <td>CA</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2023</td>\n",
       "      <td>SE</td>\n",
       "      <td>FT</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>147100</td>\n",
       "      <td>USD</td>\n",
       "      <td>147100</td>\n",
       "      <td>US</td>\n",
       "      <td>0</td>\n",
       "      <td>US</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   work_year experience_level employment_type                 job_title  \\\n",
       "0       2023               SE              FT  Principal Data Scientist   \n",
       "1       2023               MI              CT               ML Engineer   \n",
       "2       2023               MI              CT               ML Engineer   \n",
       "3       2023               SE              FT            Data Scientist   \n",
       "4       2023               SE              FT            Data Scientist   \n",
       "5       2023               SE              FT         Applied Scientist   \n",
       "6       2023               SE              FT         Applied Scientist   \n",
       "7       2023               SE              FT            Data Scientist   \n",
       "8       2023               SE              FT            Data Scientist   \n",
       "9       2023               SE              FT            Data Scientist   \n",
       "\n",
       "   salary salary_currency  salary_in_usd employee_residence  remote_ratio  \\\n",
       "0   80000             EUR          85847                 ES           100   \n",
       "1   30000             USD          30000                 US           100   \n",
       "2   25500             USD          25500                 US           100   \n",
       "3  175000             USD         175000                 CA           100   \n",
       "4  120000             USD         120000                 CA           100   \n",
       "5  222200             USD         222200                 US             0   \n",
       "6  136000             USD         136000                 US             0   \n",
       "7  219000             USD         219000                 CA             0   \n",
       "8  141000             USD         141000                 CA             0   \n",
       "9  147100             USD         147100                 US             0   \n",
       "\n",
       "  company_location company_size  \n",
       "0               ES            L  \n",
       "1               US            S  \n",
       "2               US            S  \n",
       "3               CA            M  \n",
       "4               CA            M  \n",
       "5               US            L  \n",
       "6               US            L  \n",
       "7               CA            M  \n",
       "8               CA            M  \n",
       "9               US            M  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"./ds_salaries.csv\")\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark import SparkContext\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName('Assignment').getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://192.168.1.68:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.2.4</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Assignment</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x2a01a8f2eb0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------------+---------------+--------------------+------+---------------+-------------+------------------+------------+----------------+------------+\n",
      "|      _c0|             _c1|            _c2|                 _c3|   _c4|            _c5|          _c6|               _c7|         _c8|             _c9|        _c10|\n",
      "+---------+----------------+---------------+--------------------+------+---------------+-------------+------------------+------------+----------------+------------+\n",
      "|work_year|experience_level|employment_type|           job_title|salary|salary_currency|salary_in_usd|employee_residence|remote_ratio|company_location|company_size|\n",
      "|     2023|              SE|             FT|Principal Data Sc...| 80000|            EUR|        85847|                ES|         100|              ES|           L|\n",
      "|     2023|              MI|             CT|         ML Engineer| 30000|            USD|        30000|                US|         100|              US|           S|\n",
      "|     2023|              MI|             CT|         ML Engineer| 25500|            USD|        25500|                US|         100|              US|           S|\n",
      "|     2023|              SE|             FT|      Data Scientist|175000|            USD|       175000|                CA|         100|              CA|           M|\n",
      "|     2023|              SE|             FT|      Data Scientist|120000|            USD|       120000|                CA|         100|              CA|           M|\n",
      "|     2023|              SE|             FT|   Applied Scientist|222200|            USD|       222200|                US|           0|              US|           L|\n",
      "|     2023|              SE|             FT|   Applied Scientist|136000|            USD|       136000|                US|           0|              US|           L|\n",
      "|     2023|              SE|             FT|      Data Scientist|219000|            USD|       219000|                CA|           0|              CA|           M|\n",
      "|     2023|              SE|             FT|      Data Scientist|141000|            USD|       141000|                CA|           0|              CA|           M|\n",
      "|     2023|              SE|             FT|      Data Scientist|147100|            USD|       147100|                US|           0|              US|           M|\n",
      "|     2023|              SE|             FT|      Data Scientist| 90700|            USD|        90700|                US|           0|              US|           M|\n",
      "|     2023|              SE|             FT|        Data Analyst|130000|            USD|       130000|                US|         100|              US|           M|\n",
      "|     2023|              SE|             FT|        Data Analyst|100000|            USD|       100000|                US|         100|              US|           M|\n",
      "|     2023|              EN|             FT|   Applied Scientist|213660|            USD|       213660|                US|           0|              US|           L|\n",
      "|     2023|              EN|             FT|   Applied Scientist|130760|            USD|       130760|                US|           0|              US|           L|\n",
      "|     2023|              SE|             FT|        Data Modeler|147100|            USD|       147100|                US|           0|              US|           M|\n",
      "|     2023|              SE|             FT|        Data Modeler| 90700|            USD|        90700|                US|           0|              US|           M|\n",
      "|     2023|              SE|             FT|      Data Scientist|170000|            USD|       170000|                US|           0|              US|           M|\n",
      "|     2023|              SE|             FT|      Data Scientist|150000|            USD|       150000|                US|           0|              US|           M|\n",
      "+---------+----------------+---------------+--------------------+------+---------------+-------------+------------------+------------+----------------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark = spark.read.csv(\"./ds_salaries.csv\");\n",
    "df_pyspark.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### parallelize example\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [1,2,3,4,5]\n",
    "rdd = sc.parallelize(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "map(): [2, 4, 6, 8, 10]\n"
     ]
    }
   ],
   "source": [
    "data = [1,2,3,4,5]\n",
    "rdd = sc.parallelize(data)\n",
    "squred_root = rdd.map(lambda x: x*2);\n",
    "# print(\"first()\", squred_root.first());\n",
    "print(\"map():\", squred_root.collect())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load dataset with header as column names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------------+---------------+--------------------+------+---------------+-------------+------------------+------------+----------------+------------+\n",
      "|work_year|experience_level|employment_type|           job_title|salary|salary_currency|salary_in_usd|employee_residence|remote_ratio|company_location|company_size|\n",
      "+---------+----------------+---------------+--------------------+------+---------------+-------------+------------------+------------+----------------+------------+\n",
      "|     2023|              SE|             FT|Principal Data Sc...| 80000|            EUR|        85847|                ES|         100|              ES|           L|\n",
      "|     2023|              MI|             CT|         ML Engineer| 30000|            USD|        30000|                US|         100|              US|           S|\n",
      "|     2023|              MI|             CT|         ML Engineer| 25500|            USD|        25500|                US|         100|              US|           S|\n",
      "|     2023|              SE|             FT|      Data Scientist|175000|            USD|       175000|                CA|         100|              CA|           M|\n",
      "|     2023|              SE|             FT|      Data Scientist|120000|            USD|       120000|                CA|         100|              CA|           M|\n",
      "|     2023|              SE|             FT|   Applied Scientist|222200|            USD|       222200|                US|           0|              US|           L|\n",
      "|     2023|              SE|             FT|   Applied Scientist|136000|            USD|       136000|                US|           0|              US|           L|\n",
      "|     2023|              SE|             FT|      Data Scientist|219000|            USD|       219000|                CA|           0|              CA|           M|\n",
      "|     2023|              SE|             FT|      Data Scientist|141000|            USD|       141000|                CA|           0|              CA|           M|\n",
      "|     2023|              SE|             FT|      Data Scientist|147100|            USD|       147100|                US|           0|              US|           M|\n",
      "|     2023|              SE|             FT|      Data Scientist| 90700|            USD|        90700|                US|           0|              US|           M|\n",
      "|     2023|              SE|             FT|        Data Analyst|130000|            USD|       130000|                US|         100|              US|           M|\n",
      "|     2023|              SE|             FT|        Data Analyst|100000|            USD|       100000|                US|         100|              US|           M|\n",
      "|     2023|              EN|             FT|   Applied Scientist|213660|            USD|       213660|                US|           0|              US|           L|\n",
      "|     2023|              EN|             FT|   Applied Scientist|130760|            USD|       130760|                US|           0|              US|           L|\n",
      "|     2023|              SE|             FT|        Data Modeler|147100|            USD|       147100|                US|           0|              US|           M|\n",
      "|     2023|              SE|             FT|        Data Modeler| 90700|            USD|        90700|                US|           0|              US|           M|\n",
      "|     2023|              SE|             FT|      Data Scientist|170000|            USD|       170000|                US|           0|              US|           M|\n",
      "|     2023|              SE|             FT|      Data Scientist|150000|            USD|       150000|                US|           0|              US|           M|\n",
      "|     2023|              MI|             FT|        Data Analyst|150000|            USD|       150000|                US|         100|              US|           M|\n",
      "+---------+----------------+---------------+--------------------+------+---------------+-------------+------------------+------------+----------------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark_data = spark.read.option('header', 'true').csv(\"./ds_salaries.csv\")\n",
    "spark_data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(work_year='2023', experience_level='SE', employment_type='FT', job_title='Principal Data Scientist', salary='80000', salary_currency='EUR', salary_in_usd='85847', employee_residence='ES', remote_ratio='100', company_location='ES', company_size='L'),\n",
       " Row(work_year='2023', experience_level='MI', employment_type='CT', job_title='ML Engineer', salary='30000', salary_currency='USD', salary_in_usd='30000', employee_residence='US', remote_ratio='100', company_location='US', company_size='S'),\n",
       " Row(work_year='2023', experience_level='MI', employment_type='CT', job_title='ML Engineer', salary='25500', salary_currency='USD', salary_in_usd='25500', employee_residence='US', remote_ratio='100', company_location='US', company_size='S'),\n",
       " Row(work_year='2023', experience_level='SE', employment_type='FT', job_title='Data Scientist', salary='175000', salary_currency='USD', salary_in_usd='175000', employee_residence='CA', remote_ratio='100', company_location='CA', company_size='M'),\n",
       " Row(work_year='2023', experience_level='SE', employment_type='FT', job_title='Data Scientist', salary='120000', salary_currency='USD', salary_in_usd='120000', employee_residence='CA', remote_ratio='100', company_location='CA', company_size='M'),\n",
       " Row(work_year='2023', experience_level='SE', employment_type='FT', job_title='Applied Scientist', salary='222200', salary_currency='USD', salary_in_usd='222200', employee_residence='US', remote_ratio='0', company_location='US', company_size='L'),\n",
       " Row(work_year='2023', experience_level='SE', employment_type='FT', job_title='Applied Scientist', salary='136000', salary_currency='USD', salary_in_usd='136000', employee_residence='US', remote_ratio='0', company_location='US', company_size='L'),\n",
       " Row(work_year='2023', experience_level='SE', employment_type='FT', job_title='Data Scientist', salary='219000', salary_currency='USD', salary_in_usd='219000', employee_residence='CA', remote_ratio='0', company_location='CA', company_size='M'),\n",
       " Row(work_year='2023', experience_level='SE', employment_type='FT', job_title='Data Scientist', salary='141000', salary_currency='USD', salary_in_usd='141000', employee_residence='CA', remote_ratio='0', company_location='CA', company_size='M'),\n",
       " Row(work_year='2023', experience_level='SE', employment_type='FT', job_title='Data Scientist', salary='147100', salary_currency='USD', salary_in_usd='147100', employee_residence='US', remote_ratio='0', company_location='US', company_size='M')]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark_data.head(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
